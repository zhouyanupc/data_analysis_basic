# 生成词云
from wordcloud import WordCloud
from nltk.tokenize import word_tokenize


# 去掉停用词
def remove_stop_words(f):
    stop_words = ['nan']
    for stop_word in stop_words:
        f = f.replace(stop_word,'')
    return f
# 生成词云
def create_word_cloud(f):
    f = remove_stop_words(f)
    cut_text = word_tokenize(f)
    cut_text = " ".join(cut_text)
    wc = WordCloud(
        max_words=100,
        width=2000,
        height=1200,
    )
    wordcloud = wc.generate(cut_text)
    wordcloud.to_file("wordcloud.jpg")
    plt.imshow(wordcloud)
    plt.axis('off')
    plt.show()
# 数据加载
data = pd.read_csv('./Market_Basket_Optimisation.csv',header=None)
transactions = []
for i in range(0,data.shape[0]):
    transactions.append([str(data.values[i,j]) for j in range(0,20)])
all_word = " ".join('%s'%id for id in transactions)
print(all_word)
create_word_cloud(all_word)
